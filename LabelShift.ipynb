{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff48ec6a-8760-4059-93d8-3941b871a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from utils import *\n",
    "data = loadmat('emnist-digits.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00905d30-b071-4b7d-99b1-64266e8e742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e6610d-be6a-4158-86a4-1d35b573b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data['dataset'][0, 0]\n",
    "train = dataset[0][0, 0]  \n",
    "test = dataset[1][0, 0]  \n",
    "mapping = dataset[2]\n",
    "\n",
    "train_images = train['images']   # Shape: (N, 28*28)\n",
    "train_labels = train['labels']  # Shape: (N, 1)\n",
    "train_writers = train['writers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4714ba0d-3b54-4b1a-9723-3cdd6e691cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_images.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "y = train_labels.flatten().astype(np.int64)\n",
    "\n",
    "# Wrap into a datalist with a single client\n",
    "datalist = [(X, y)]\n",
    "\n",
    "test_images = test['images'].astype(np.float32) / 255.0\n",
    "test_labels = test['labels'].flatten().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f34fb4c-7cca-478b-ace6-8543de11ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labels_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f366af4a-1dcc-4073-8f32-89e997c7d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training the baseline, i.e. fedAvg with one client holding all the data\n",
      "round :  1\n",
      "round :  2\n",
      "round :  3\n",
      "round :  4\n",
      "round :  5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "T = 5       # number of global rounds\n",
    "K = 10      # number of client GD steps\n",
    "gamma = 0.1 # learning rate\n",
    "\n",
    "# Run FedAvg with 1 client\n",
    "print(\"now training the baseline, i.e. fedAvg with one client holding all the data\")\n",
    "model = fedavg(datalist, T, K, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93104499-2f8e-47ca-a101-6d8481a0a12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.58%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_accuracy = evaluate(model, test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "553cc35f-7e84-4377-86af-e47023832dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case with 5 clients, beta=0.5 skewed distribution!\n",
      "round :  1\n",
      "round :  2\n",
      "round :  3\n",
      "round :  4\n",
      "round :  5\n"
     ]
    }
   ],
   "source": [
    "n_clients = 5\n",
    "beta = 0.5 \n",
    "datalist = create_dirichlet_clients(X, y, n_clients, beta)\n",
    "\n",
    "# Hyperparameters\n",
    "T = 5       # number of global rounds\n",
    "K = 10      # number of client GD steps\n",
    "gamma = 0.1 # learning rate\n",
    "print(\"case with 5 clients, beta=0.5 skewed distribution!\")\n",
    "model = fedavg(datalist, T, K, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b636ec-9a2a-4b33-847c-e4926530ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with 5 clients and Dir(0.5): 72.24%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_accuracy = evaluate(model, test_images, test_labels)\n",
    "print(f\"Test Accuracy with {n_clients} clients and Dir({beta}): {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61859fa6-aa3d-46ad-84a3-815b447f05d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case with 5 clients, beta=10^5, which means close to IID clients (baseline 2)!\n",
      "round :  1\n",
      "round :  2\n",
      "round :  3\n",
      "round :  4\n",
      "round :  5\n"
     ]
    }
   ],
   "source": [
    "n_clients = 5\n",
    "beta = 1e5\n",
    "datalist = create_dirichlet_clients(X, y, n_clients, beta)\n",
    "\n",
    "# Hyperparameters\n",
    "T = 5       # number of global rounds\n",
    "K = 10      # number of client GD steps\n",
    "gamma = 0.1 # learning rate\n",
    "print(\"case with 5 clients, beta=10^5, which means close to IID clients (baseline 2)!\")\n",
    "model = fedavg(datalist, T, K, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7956a33e-da06-4fb5-a6cf-c5b5db3fe46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with 5 clients and Dir(100000.0): 84.07%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_accuracy = evaluate(model, test_images, test_labels)\n",
    "print(f\"Test Accuracy with {n_clients} clients and Dir({beta}): {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90fe6071-cfb2-4c4a-9a12-63f7cfc19188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case with 5 clients, beta=0.5 skewed distribution, with weights based on the inverse KL-divergence\n",
      "round :  1\n",
      "round :  2\n",
      "round :  3\n",
      "round :  4\n",
      "round :  5\n"
     ]
    }
   ],
   "source": [
    "n_clients = 5\n",
    "beta = 0.5 \n",
    "datalist = create_dirichlet_clients(X, y, n_clients, beta)\n",
    "\n",
    "# Hyperparameters\n",
    "T = 5       # number of global rounds\n",
    "K = 10      # number of client GD steps\n",
    "gamma = 0.1 # learning rate\n",
    "print(\"case with 5 clients, beta=0.5 skewed distribution, with weights based on the inverse KL-divergence\")\n",
    "weights = compute_inverse_kl_weights(datalist)\n",
    "model = fedavg(datalist, T=5, K=10, gamma=0.1, weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b957960-3f94-4d37-be22-53d095889896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6942750215530396\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate(model, test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd0ff9",
   "metadata": {},
   "source": [
    "### Testing the Moon Federated learning on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0e6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26d68b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 5\n",
    "beta = 0.5 \n",
    "datalist = create_dirichlet_clients(X, y, n_clients, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0147f3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case with 5 clients, beta=0.5 skewed distribution!\n",
      "round :  1\n",
      "round :  2\n",
      "round :  3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;66;03m# learning rate\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcase with 5 clients, beta=0.5 skewed distribution!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m fedavg(datalist, T, K, gamma)\n",
      "File \u001b[0;32m~/Desktop/epfl/Courses/GitHub/miniproject_OPTML/utils.py:93\u001b[0m, in \u001b[0;36mfedavg\u001b[0;34m(datalist, T, K, gamma, weights)\u001b[0m\n\u001b[1;32m     90\u001b[0m     X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     91\u001b[0m     y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m---> 93\u001b[0m     client_model \u001b[38;5;241m=\u001b[39m client_update(client_model, X_tensor, y_tensor, K, gamma)\n\u001b[1;32m     94\u001b[0m     local_states\u001b[38;5;241m.\u001b[39mappend(deepcopy(client_model\u001b[38;5;241m.\u001b[39mstate_dict()))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Weighted Federated Averaging\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/epfl/Courses/GitHub/miniproject_OPTML/utils.py:39\u001b[0m, in \u001b[0;36mclient_update\u001b[0;34m(model, data, target, K, gamma)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclient_update\u001b[39m(model, data, target, K, gamma):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[0;32m---> 39\u001b[0m         model \u001b[38;5;241m=\u001b[39m gd_step(model, data, target, gamma)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/epfl/Courses/GitHub/miniproject_OPTML/utils.py:31\u001b[0m, in \u001b[0;36mgd_step\u001b[0;34m(model, data, target, gamma)\u001b[0m\n\u001b[1;32m     29\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n\u001b[0;32m---> 31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[1;32m    354\u001b[0m     tensors,\n\u001b[1;32m    355\u001b[0m     grad_tensors_,\n\u001b[1;32m    356\u001b[0m     retain_graph,\n\u001b[1;32m    357\u001b[0m     create_graph,\n\u001b[1;32m    358\u001b[0m     inputs,\n\u001b[1;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "T = 5       # number of global rounds\n",
    "K = 10      # number of client GD steps\n",
    "gamma = 0.1 # learning rate\n",
    "print(\"case with 5 clients, beta=0.5 skewed distribution!\")\n",
    "model = fedavg(datalist, T, K, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1152fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7438250184059143\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate(model, test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92eb0487-ea0f-4437-9bac-218a5bd4d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_curve = fedavg_moon(datalist, T=5, K=10, gamma=0.1, mu=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e03b09c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8203250169754028\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate(model, test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d22625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
